# -*- coding: utf-8 -*-
"""dataset preparation .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kJJuZ7rTqoOwBk0Q9sH26zegflSPcsQH

## Upload
"""

#uploader just in case
from google.colab import files
uploaded = files.upload()

#credits to: 
#https://colab.research.google.com/github/TannerGilbert/Object-Detection-and-Image-Segmentation-with-Detectron2/blob/master/Detectron2_train_and_export_model.ipynb#scrollTo=Y19zWbMmnWlz
#https://colab.research.google.com/drive/1-TNOcPm3Jr3fOJG8rnGT9gh60mHUsvaW#scrollTo=BdTAusKE9zUQ
#https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5#scrollTo=hBXeH8UXFcqU

#mount drive with dataset

"""## Set Up"""

!pip install pyyaml==5.1
import torch, torchvision
print(torch.__version__, torch.cuda.is_available())
!gcc --version

import torchvision.transforms as tf

assert torch.__version__.startswith("1.8")
print(torch.__version__)

exit(0) #if asks to restart runtime

#if torch.cuda.is_available() = False
#runtime->change runtime type->gpu or just leave it as it is

import numpy as np
import cv2
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt

import glob
import shutil
import os
import json
from PIL import Image
import time
import random

"""## Datasets

once done, can be ignored

segmentation dataset
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/sipakmed_dataset
# %ls

# Commented out IPython magic to ensure Python compatibility.
# %mkdir detection_dataset

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/sipakmed_dataset/detection_dataset
# %mkdir /content/drive/MyDrive/sipakmed_dataset/detection_dataset/images
# %mkdir /content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries
# %ls

glob_path = '/content/drive/MyDrive/sipakmed_dataset'
target1 = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/images'
target2 = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries'

#renaming files according to class labels

ls = os.listdir(glob_path)
for i in range(5):
  print(ls[i])
  path = os.path.join(glob_path, ls[i])
  for _, _, files in os.walk(path):
    for f in files:
      filename = os.path.join(path, f)
      newfilename = os.path.join(path, ls[i] + '_' + f)
      os.rename(filename, newfilename)

#note: if gives Errno2, range(i,5) -> range(i+1, 5)
#or create exception

#should be ~1682, 1849, 1888, 1857, 1752
print(len([name for name in os.listdir('/content/drive/MyDrive/sipakmed_dataset/im_Parabasal') if os.path.isfile(os.path.join('/content/drive/MyDrive/sipakmed_dataset/im_Parabasal', name))]))
print(len([name for name in os.listdir('/content/drive/MyDrive/sipakmed_dataset/im_Dyskeratotic') if os.path.isfile(os.path.join('/content/drive/MyDrive/sipakmed_dataset/im_Dyskeratotic', name))]))
print(len([name for name in os.listdir('/content/drive/MyDrive/sipakmed_dataset/im_Koilocytotic') if os.path.isfile(os.path.join('/content/drive/MyDrive/sipakmed_dataset/im_Koilocytotic', name))]))
print(len([name for name in os.listdir('/content/drive/MyDrive/sipakmed_dataset/im_Metaplastic') if os.path.isfile(os.path.join('/content/drive/MyDrive/sipakmed_dataset/im_Metaplastic', name))]))
print(len([name for name in os.listdir('/content/drive/MyDrive/sipakmed_dataset/im_Superficial-Intermediate') if os.path.isfile(os.path.join('/content/drive/MyDrive/sipakmed_dataset/im_Superficial-Intermediate', name))]))

#should be ~966, (8042 or 4021)
seg_len_im = len([name for name in os.listdir(target1) if os.path.isfile(os.path.join(target1, name))])
seg_len_b = len([name for name in os.listdir(target2) if os.path.isfile(os.path.join(target2, name))])
print(seg_len_im)
print(seg_len_b)

#utilitary, clean detection_dataset directories

files = glob.glob('/content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries/*')
for f in files:
    os.remove(f)

files = glob.glob('/content/drive/MyDrive/sipakmed_dataset/detection_dataset/images/*')
for f in files:
    os.remove(f)

#debugging wrong renames
for i in range(5):
  print(ls[i])
  path = os.path.join(glob_path, ls[i])
  for _, _, files in os.walk(path):
    for f in files:
      if (f.startswith('im_Parabasal_im_Parabasal')):
          newf = f.replace('im_Parabasal_im_Parabasal', 'im_Parabasal')
          filename = os.path.join(path, f)
          newfilename = os.path.join(path, newf)
          os.rename(filename, newfilename)
      elif (f.startswith('im_Dyskeratoric_im_Dyskeratoric')):
          newf = f.replace('im_Dyskeratoric_im_Dyskeratoric', 'im_Dyskeratoric')
          filename = os.path.join(path, f)
          newfilename = os.path.join(path, newf)
          os.rename(filename, newfilename)
      elif (f.startswith('im_Koilocytotic_im_Koilocytotic')):
          newf = f.replace('im_Koilocytotic_im_Koilocytotic', 'im_Koilocytotic')
          filename = os.path.join(path, f)
          newfilename = os.path.join(path, newf)
          os.rename(filename, newfilename)
      elif (f.startswith('im_Metaplastic_im_Metaplastic')):
          newf = f.replace('im_Metaplastic_im_Metaplastic', 'im_Metaplastic')
          filename = os.path.join(path, f)
          newfilename = os.path.join(path, newf)
          os.rename(filename, newfilename)
      elif (f.startswith('im_Superficial-Intermediate_im_Superficial-Intermediate')):
          newf = f.replace('im_Superficial-Intermediate_im_Superficial-Intermediate', 'im_Superficial-Intermediate')
          filename = os.path.join(path, f)
          newfilename = os.path.join(path, newf)
          os.rename(filename, newfilename)

#copying files into segmentation_dataset
for i in range(4,5):
  print(ls[i])
  path = os.path.join(glob_path, ls[i])
  for _, _, files in os.walk(path):
    for f in files:
      if f.endswith('.bmp'):
          shutil.copyfile(os.path.join(glob_path, ls[i] + '/' + f), os.path.join(target1, f))
      else:
          shutil.copyfile(os.path.join(glob_path, ls[i] + '/' + f), os.path.join(target2, f))

#removing nuclei boundaries
for i in os.listdir(target2):
    if os.path.isfile(os.path.join(target2,i)) and 'nuc' in i:
        os.remove(os.path.join(target2,i))

"""Classification dataset"""

# Commented out IPython magic to ensure Python compatibility.
# %mkdir '/content/drive/MyDrive/sipakmed_dataset/classification_dataset'
# %mkdir '/content/drive/MyDrive/sipakmed_dataset/classification_dataset/t'
# %mkdir '/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Koilocytotic'
# %mkdir '/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Metaplastic'
# %mkdir '/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Parabasal'
# %mkdir '/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Superficial-Intermediate'

files = glob.glob('/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Superficial-Intermediate/*')
for f in files:
    os.remove(f)

path_cl = '/content/drive/MyDrive/sipakmed_dataset/'
ls_cl = ['im_Parabasal', 'im_Koilocytotic', 'im_Superficial-Intermediate', 'im_Dyskeratotic', 'im_Metaplastic']
path_ds = '/content/drive/MyDrive/sipakmed_dataset/classification_dataset/'
for i in range(2,3):
  path_cl_tmp = path_cl + ls_cl[i] + '/CROPPED'
  path_ds_tmp = path_ds + ls_cl[i]
  print(path_cl_tmp)
  for _, _, fs in os.walk(path_cl_tmp):
    for f in fs:
      if f.endswith('.bmp'):
        shutil.copyfile(os.path.join(path_cl_tmp, f), os.path.join(path_ds_tmp, f))

#should be ~787, 813, 825, 793, 813
p_len = len([name for name in os.listdir('/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Parabasal') 
  if os.path.isfile(os.path.join('/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Parabasal', name))])
d_len = len([name for name in os.listdir('/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Dyskeratotic') 
  if os.path.isfile(os.path.join('/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Dyskeratotic', name))])
k_len = len([name for name in os.listdir('/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Koilocytotic') 
  if os.path.isfile(os.path.join('/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Koilocytotic', name))])
m_len = len([name for name in os.listdir('/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Metaplastic') 
  if os.path.isfile(os.path.join('/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Metaplastic', name))])
s_len = len([name for name in os.listdir('/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Superficial-Intermediate') 
  if os.path.isfile(os.path.join('/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Superficial-Intermediate', name))])

print(p_len, d_len, k_len, m_len, s_len)

def check_res(path):
  img = Image.open(path)
  tfm = tf.ToTensor()
  img = tfm(img)
  size = img.size()
  return size

check_res('/content/drive/MyDrive/sipakmed_dataset/detection_dataset/images/im_Dyskeratotic_001.bmp')

#calculate mean resolution and reshape each image
def rescale_by_path(path):
  img = Image.open(path)
  
  tfm1 = tf.ToTensor()
  img = tfm1(img)
  tfm2 = tf.Compose([tf.Resize((100,100))])
  img = tfm2(img).numpy().transpose((1, 2, 0))
  img = tfm1(img)
  size = img.size()
  tfm3 = tf.ToPILImage()
  img = tfm3(img)
  img = img.save(path)

def rescale_by_img(img):
  
  tfm1 = tf.ToTensor()
  img = tfm1(img)
  tfm2 = tf.Compose([tf.Resize((100,100))])
  img = tfm2(img).numpy().transpose((1, 2, 0))
  img = tfm1(img)
  size = img.size()
  tfm3 = tf.ToPILImage()
  img = tfm3(img)
  img = img.save(path)

dir_list = ['/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Dyskeratotic',
            '/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Koilocytotic',
            '/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Metaplastic',
            '/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Parabasal',
            '/content/drive/MyDrive/sipakmed_dataset/classification_dataset/im_Superficial-Intermediate']

for dir in dir_list:
  print(dir)
  img_list = glob.glob(dir + '/*')
  for img in img_list:
    path = os.path.join(dir + img)
    rescale_by_path(img)

"""segementation dataset ctnd, making it coco compatible for detectron2"""

dt_dir = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset'

def create_img_id(path):
    path = path.replace('/content/drive/MyDrive/sipakmed_dataset/detection_dataset/images/im_', '')
    path = path.replace('.bmp', '')
    last = path[-3:]
    first = path[0]
    id = first + last 
    return id

def path_from_img_id(img_id):
    if (img_id[0] == 'S'):
        img_id = img_id.replace('S', 'Superficial-Intermediate_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/images/im_' + img_id + '.bmp'
    elif (img_id[0] == 'P'):
        img_id = img_id.replace('P', 'Parabasal_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/images/im_' + img_id + '.bmp'
    elif (img_id[0] == 'K'):
        img_id = img_id.replace('K', 'Koilocytotic_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/images/im_' + img_id + '.bmp'
    elif (img_id[0] == 'M'):
        img_id = img_id.replace('M', 'Metaplastic_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/images/im_' + img_id + '.bmp'
    elif (img_id[0] == 'D'):
        img_id = img_id.replace('D', 'Dyskeratotic_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/images/im_' + img_id + '.bmp'

    return path

def path_from_id_pair(img_id, c_mem):
    if (img_id[0] == 'S'):
        img_id = img_id.replace('S', 'Superficial-Intermediate_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries/im_' + img_id + '_cyt' + c_mem + '.dat'
    elif (img_id[0] == 'P'):
        img_id = img_id.replace('P', 'Parabasal_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries/im_' + img_id + '_cyt' + c_mem + '.dat'
    elif (img_id[0] == 'K'):
        img_id = img_id.replace('K', 'Koilocytotic_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries/im_' + img_id + '_cyt' + c_mem + '.dat'
    elif (img_id[0] == 'M'):
        img_id = img_id.replace('M', 'Metaplastic_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries/im_' + img_id + '_cyt' + c_mem + '.dat'
    elif (img_id[0] == 'D'):
        img_id = img_id.replace('D', 'Dyskeratotic_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries/im_' + img_id + '_cyt' + c_mem + '.dat'

    return path

def crowd_size(img_id):
    if (img_id[0] == 'S'):
        img_id = img_id.replace('S', 'Superficial-Intermediate_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries/im_' + img_id + '*'
    elif (img_id[0] == 'P'):
        img_id = img_id.replace('P', 'Parabasal_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries/im_' + img_id + '*'
    elif (img_id[0] == 'K'):
        img_id = img_id.replace('K', 'Koilocytotic_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries/im_' + img_id + '*'
    elif (img_id[0] == 'M'):
        img_id = img_id.replace('M', 'Metaplastic_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries/im_' + img_id + '*'
    elif (img_id[0] == 'D'):
        img_id = img_id.replace('D', 'Dyskeratotic_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries/im_' + img_id + '*'

    crowd = glob.glob(path)
    return len(crowd)

def extract_boundaries(img_id, c_mem):
    path = path_from_id_pair(img_id, c_mem)
    
    temp = [i.strip().split(',') for i in open(path).readlines()]
    temp_np = np.array(temp)
    a, b = temp_np.shape

    np_arr = np.zeros([a, b], dtype=np.float64)

    for i in range(a):
        for j in range(b):
            k = temp_np[i, j].astype(np.float)
            np_arr[i, j] = k

    x_max = np.amax(np_arr[:,0])
    x_min = np.amin(np_arr[:,0])
    y_max = np.amax(np_arr[:,1])
    y_min = np.amin(np_arr[:,1])

    return x_min, x_max, y_min, y_max

def create_segmentation(img_id, crowd_member):
    if (img_id[0] == 'S'):
        img_id = img_id.replace('S', 'Superficial-Intermediate_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries/im_' + img_id + '_cyt' + crowd_member + '.dat'
    elif (img_id[0] == 'P'):
        img_id = img_id.replace('P', 'Parabasal_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries/im_' + img_id + '_cyt' + crowd_member + '.dat'
    elif (img_id[0] == 'K'):
        img_id = img_id.replace('K', 'Koilocytotic_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries/im_' + img_id + '_cyt' + crowd_member + '.dat'
    elif (img_id[0] == 'M'):
        img_id = img_id.replace('M', 'Metaplastic_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries/im_' + img_id + '_cyt' + crowd_member + '.dat'
    elif (img_id[0] == 'D'):
        img_id = img_id.replace('D', 'Dyskeratotic_')
        path = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries/im_' + img_id + '_cyt' + crowd_member + '.dat'

    temp = [i.strip().split(',') for i in open(path).readlines()]
    temp_np = np.array(temp)
    a, b = temp_np.shape

    np_arr = np.zeros([a, b], dtype=np.float64)

    for i in range(a):
        for j in range(b):
            k = temp_np[i, j].astype(np.float)
            np_arr[i, j] = k
    
    segmentation = []
    for i in range(a - 1):
        xn = np_arr[i, 0]
        yn = np_arr[i, 1]
        segmentation.append(xn)
        segmentation.append(yn)

    segmentation = [segmentation]
    
    return segmentation

def extract_dim(img_id, crowd_member):
  x_min, x_max, y_min, y_max = extract_boundaries(img_id, crowd_member)
  width = x_max - x_min
  height = y_max - y_min
  
  return width, height

def create_area(img_id, crowd_member):
  width, height = extract_dim(img_id, crowd_member)

  return width * height

def create_bbox(img_id, crowd_member):
    x_min, x_max , y_min, y_max = extract_boundaries(img_id, crowd_member)
    width, height = extract_dim(img_id, crowd_member)
    bbox = [x_min, y_min, width, height]

    return bbox

#debugging
def are_b_fine(path):
    temp = [i.strip().split(',') for i in open(path).readlines()]
    temp_np = np.array(temp)
    if temp_np.ndim != 2:
      return path
    else:
      return True

#debugging
files = glob.glob('/content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries/*')
corrupted = []
j = 0

for file in files:
  j += 1
  if (j % 100) == 0:
    print(j)

  path = os.path.join('/content/drive/MyDrive/sipakmed_dataset/detection_dataset/boundaries', file)
  if are_b_fine(path) == True:
    continue
  else:
    corrupted.append(path)

print("done")

def create_id_list(dir):
  id_list = []
  
  files = glob.glob(dir + '/*')
  for file in files:
    path = os.path.join(dir, file)
    img_id = create_img_id(path)
    c_size = crowd_size(img_id)

    for i in range(c_size):
        if i <= 8:
            c_mem = '0' + str(i + 1)
        else:
            c_mem = str(i + 1)
        id_pair = [img_id, c_mem]
        id_list.append(id_pair)

  return id_list

len_seg = seg_len_b
dir_seg = '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/images'
len_seg_train = int(len_seg * 0.7)
len_seg_val = int(len_seg * 0.15)
len_seg_test = len_seg - len_seg_train - len_seg_val
print(len_seg_train, len_seg_val, len_seg_test)

id_list = create_id_list(dir_seg)
random.shuffle(id_list)
id_list_train = id_list[0:len_seg_train]
id_list_val = id_list[len_seg_train:(len_seg_train + len_seg_val)]
id_list_test = id_list[(len_seg_train + len_seg_val):(len_seg)]
print(len(id_list_train), len(id_list_val), len(id_list_test))

# Commented out IPython magic to ensure Python compatibility.
# %mkdir '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/images_train'
# %mkdir '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/images_val'
# %mkdir '/content/drive/MyDrive/sipakmed_dataset/detection_dataset/images_test'

files = glob.glob('/content/drive/MyDrive/sipakmed_dataset/detection_dataset/images_train/*')
for f in files:
    os.remove(f)
    
files = glob.glob('/content/drive/MyDrive/sipakmed_dataset/detection_dataset/images_val/*')
for f in files:
    os.remove(f)

files = glob.glob('/content/drive/MyDrive/sipakmed_dataset/detection_dataset/images_test/*')
for f in files:
    os.remove(f)

j = 0
for id in id_list_train:
  j += 1
  
  if (j % 100) == 0:
    print("%d / %d " % (j, len(id_list_train) ))

  img_id = id[0]
  path = path_from_img_id(img_id)
  shutil.copyfile(path, path.replace('/images', '/images_train'))

  if j == (len(id_list_train) + 1):
    break

j = 0
for id in id_list_val:
  j += 1

  
  if (j % 100) == 0:
    print("%d / %d " % (j, len(id_list_val) ))

  img_id = id[0]
  path = path_from_img_id(img_id)
  shutil.copyfile(path, path.replace('/images', '/images_val'))

  if j == (len(id_list_val) + 1):
    break

j = 0
for id in id_list_test:
  j += 1

  
  if (j % 100) == 0:
    print("%d / %d " % (j, len(id_list_test) ))

  img_id = id[0]
  path = path_from_img_id(img_id)
  shutil.copyfile(path, path.replace('/images', '/images_test'))

  if j == (len(id_list_test) + 1):
    break

id_container = [id_list_train, id_list_val, id_list_test]

#debugging
def check_files(mode):
  id_list =  id_container[mode]
  corrupted = []
  j = 0

  for id in id_list:
    j += 1
    if (j % 100) == 0:
      print("%d / %d " % (j, len(id_list)) )

    img_id = id[0]
    path = path_from_img_id(img_id)

    presence = glob.glob(path)
    flag = len(presence)

    if flag == 0:
      corrupted.append(img_id)

    return corrupted

def img_id_to_int(img_id):
    img_id_int = 0
    if img_id[0] == 'D':
      img_id_int = 1 * (10**3) + int(img_id[1:])  
    elif img_id[0] == 'K':
      img_id_int = 2 * (10**3) + int(img_id[1:]) 
    elif img_id[0] == 'M':
      img_id_int = 3 * (10**3) + int(img_id[1:]) 
    elif img_id[0] == 'P':
      img_id_int = 4 * (10**3) + int(img_id[1:]) 
    elif img_id[0] == 'S':
      img_id_int = 5 * (10**3) + int(img_id[1:]) 

    return img_id_int

# json format retriever v1
def get_dicts_from_dir(dir):
    dict_list = []
    files = glob.glob(dir + '/images/*')
    j = 0

    for file in files:
      j += 1

      if (j % 100) == 0:
          print("%d / %d " % (j, len_seg) )

      path = os.path.join(dir + '/images',file)
      if (file.endswith('.bmp') == False):
        os.remove(path)
        continue

      else:
          img_id = create_img_id(path)
          c_size = crowd_size(img_id)
          _, w, h = check_res(path)

          if c_size == 1:
            is_crowd = 0
          else:
            is_crowd = 1

          annotations = []

          for i in range(c_size):
              if i <= 8:
                c_mem = '0' + str(i + 1)
              else:
                c_mem = str(i + 1)

              bbox = create_bbox(img_id, c_mem)
              segmentation = create_segmentation(img_id, c_mem)
              
              annot_dict = {
                  "bbox" : bbox,
                  "bbox_mode" : 1,
                  "category_id" : 0,
                  "segmentation" : segmentation,
                  "is_crowd" : is_crowd
              } 

              annotations.append(annot_dict)

          img_dict = {
              "file_name" : path,
              "height" :  h,
              "width" : w,
              "image_id" : img_id,
              "annotations" : annotations
          }

          dict_list.append(img_dict)
      
    return dict_list

# json format retriever v2
def get_dicts_from_list(id_list, mode):
  
  id_check = []
  images = []
  annotations = []
  dictionary = {
      "info" : 
      {
        "description" : "none",
        "url" : "none",
        "version" : "none",
        "year" : 2020,
        "contributor" : "none",
        "date_created" : "none",
      },
      "licenses" :
      [
          {
            "url" : "none",
            "id" : 1,
            "name" : "none"
          } 
      ],
      "images" : images,
      "annotations" : annotations,
      "categories" :
      [ 
          {
            "supercategory" : "none",
            "id" : 1,
            "name" : "cell"
          }
      ]
  }
  
  
  j = 0

  for id in id_list:
    flag = 0
    j += 1
    if (j % 100) == 0:
          print("%d / %d " % (j, len(id_list)) )

    img_id = id[0]
    c_mem = id[1]
    path = path_from_img_id(img_id)
    c_size = crowd_size(img_id)
    _, w, h = check_res(path)
    a = w * h

    if mode == 'train':
      file_path = path.replace('/images', '/images_train')
    elif mode == 'val':
      file_path = path.replace('/images', '/images_val')
    elif mode == 'test':
      file_path = path.replace('/images', '/images_test')

    if c_size == 1:
        iscrowd = False
    else:
        iscrowd = True

    bbox = create_bbox(img_id, c_mem)
    segmentation = create_segmentation(img_id, c_mem)

    if img_id[0] == 'D':
      img_id_int = 1 * (10**6) + int(img_id[1:]) * (10**3) + int(c_mem) * 100
    elif img_id[0] == 'K':
      img_id_int = 2 * (10**6) + int(img_id[1:]) * (10**3) + int(c_mem) * 100
    elif img_id[0] == 'M':
      img_id_int = 3 * (10**6) + int(img_id[1:]) * (10**3) + int(c_mem) * 100
    elif img_id[0] == 'P':
      img_id_int = 4 * (10**6) + int(img_id[1:]) * (10**3) + int(c_mem) * 100
    elif img_id[0] == 'S':
      img_id_int = 5 * (10**6) + int(img_id[1:]) * (10**3) + int(c_mem) * 100

    for ids in id_check:
      if ids == img_id_int:
        flag = 1

    id_check.append(img_id_int)
              
    image_dict = {
        "license" : 1,
        "file_name" : file_path,
        "coco_url" : "none",
        "height" : h,
        "width" : w,
        "date_captured" : "none",
        "flickr_url" : "none",
        "id" : img_id_int
    }

    if flag == 0:
      images.append(image_dict)

    annot_dict = {
        "segmentation" : segmentation,
        "area" : a,
        "iscrowd" : iscrowd,
        "image_id" : img_id_int + int(c_mem),
        "bbox" : bbox,
        "category_id" : 1,
        "id" : j
    }

    annotations.append(annot_dict)

  return dictionary

# json format retriever v3
def jfr3(id_list, mode):
  dict_list = []
  j = 0

  for id in id_list:
    j += 1
    if (j % 100) == 0:
          print("%d / %d " % (j, len(id_list)) )

    img_id = id[0]
    c_mem = id[1]
    path = path_from_img_id(img_id)
    c_size = crowd_size(img_id)
    _, w, h = check_res(path)

    if mode == 'train':
      file_path = path.replace('/images', '/images_train')
    elif mode == 'val':
      file_path = path.replace('/images', '/images_val')
    elif mode == 'test':
      file_path = path.replace('/images', '/images_test')

    if c_size == 1:
        is_crowd = 0
    else:
        is_crowd = 1

    annotations = []

    bbox = create_bbox(img_id, c_mem)
    segmentation = create_segmentation(img_id, c_mem)
              
    annot_dict = {
                  "bbox" : bbox,
                  "bbox_mode" : 1,
                  "category_id" : 0,
                  "segmentation" : segmentation,
                  "is_crowd" : is_crowd
                  } 

    annotations.append(annot_dict)

    img_dict = {
                "file_name" : file_path,
                "height" :  h,
                "width" : w,
                "image_id" : img_id_to_int(img_id),
                "annotations" : annotations
                }

    dict_list.append(img_dict)

  return dict_list

#debugging
def check_bound_f_presence(id):
    img_id = id[0]
    c_mem = id[1]

    path = path_from_id_pair(img_id, c_mem)
    files = glob.glob(path)

    if files == []:
      return False
    else:
      return True

#debugging
missing = []

for id in id_list:
  if check_bound_f_presence(id) == False:
    missing.append(id)

#creating dics and saving jsons
dict_list_train = jfr3(id_list_train, mode='train')
print("dict_list_train done")

with open('seg_train.json', 'w') as fout:
    json.dump(dict_list_train, fout)

dict_list_val = jfr3(id_list_val, mode='val')
print("dict_list_val done")

with open('seg_val.json', 'w') as fout:
    json.dump(dict_list_val, fout)

dict_list_test = jfr3(id_list_test, mode='test')
print("dict_list_test done")

with open('seg_test.json', 'w') as fout:
    json.dump(dict_list_test, fout)

with open('seg_train.json', 'w') as fout:
    json.dump(dict_list_train, fout)
  
with open('seg_val.json', 'w') as fout:
    json.dump(dict_list_val, fout)
  
with open('seg_test.json', 'w') as fout:
    json.dump(dict_list_test, fout)

with open('id_container.json', 'w') as fout:
    json.dump(id_container, fout)

with open('/content/id_container.json') as f:
    id_container = json.load(f)

"""## Detection/segmentation"""

!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html

exit(0) #if asks to restart runtime

import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog, DatasetCatalog
from detectron2.structures import BoxMode
from detectron2.data.datasets import register_coco_instances
from detectron2.engine import DefaultTrainer
from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.utils.visualizer import ColorMode
from detectron2.data import build_detection_test_loader

#init datasets coco style
register_coco_instances("dset_train", {}, "/content/seg_train.json", "/content/drive/MyDrive/sipakmed_dataset/detection_dataset/images_train")
register_coco_instances("dset_val", {}, "/content/seg_val.json", "/content/drive/MyDrive/sipakmed_dataset/detection_dataset/images_val")
register_coco_instances("dset_test", {}, "/content/seg_test.json", "/content/drive/MyDrive/sipakmed_dataset/detection_dataset/images_test")

def json_to_ds(path):

  with open(path) as f:
    dict_list = json.load(f)

  return dict_list

#debugging
def change_key_f(dict_list):
  for dictionary in dict_list:
    oldk = "filename"
    newk = "file_name"
    dictionary[newk] = dictionary.pop(oldk)
  return dict_list

#debugging
dict_list_train = json_to_ds("/content/seg_train.json")
dict_list_train = change_key_f(dict_list_train)

dict_list_val = json_to_ds("/content/seg_val.json")
dict_list_val = change_key_f(dict_list_val)

dict_list_test = json_to_ds("/content/seg_test.json")
dict_list_test = change_key_f(dict_list_test)

#debugging

def conv_img_id(dict_list):
    for dictionary in dict_list:
      img_id = dictionary["image_id"]
      dictionary["image_id"] = int(img_id_to_int(img_id))
    return dict_list

#debugging
dict_list_train = json_to_ds("/content/seg_train.json")
dict_list_train = conv_img_id(dict_list_train)

dict_list_val = json_to_ds("/content/seg_val.json")
dict_list_val = conv_img_id(dict_list_val)

dict_list_test = json_to_ds("/content/seg_test.json")
dict_list_test = conv_img_id(dict_list_test)

#debugging
def swap_w_h(dict_list):
  for dictionary in dict_list:
    width = "width"
    height = "height"
    buff = "buff"
    dictionary[buff] = dictionary.pop(width)
    dictionary[width] = dictionary.pop(height)
    dictionary[height] = dictionary.pop(buff)
  return dict_list

#debugging
dict_list_train = json_to_ds("/content/seg_train.json")
dict_list_train = swap_w_h(dict_list_train)

dict_list_val = json_to_ds("/content/seg_val.json")
dict_list_val = swap_w_h(dict_list_val)

dict_list_test = json_to_ds("/content/seg_test.json")
dict_list_test = swap_w_h(dict_list_test)

#debugging
def ch(listOfElems):
    ''' Check if given list contains any duplicates '''    
    for elem in listOfElems:
        if listOfElems.count(elem) > 1:
            return True
    return False

#debugging
corrupted_c = []
for lists in id_container:
  c = ch(lists)
  corrupted_c.append(c)

with open('seg_train.json', 'w') as fout:
    json.dump(dict_list_train, fout)
  
with open('seg_val.json', 'w') as fout:
    json.dump(dict_list_val, fout)
  
with open('seg_test.json', 'w') as fout:
    json.dump(dict_list_test, fout)

#register custom dataset
mode_list = ["train", "val", "test"]
path1 = "/content/seg_"


for mode in mode_list:
  DatasetCatalog.register("ds9_" + mode, lambda mode=mode: json_to_ds(path1 + mode + ".json"))
  MetadataCatalog.get("ds9_" + mode).set(thing_classes=["cell"])

cell_meta = MetadataCatalog.get("ds9_train")

#hyperparams
cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/retinanet_R_50_FPN_1x.yaml")) #TBD, this arch for now
cfg.DATASETS.TRAIN = ("ds9_train",) # 
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5 #have this for now
cfg.DATASETS.TEST = () #

cfg.DATALOADER.NUM_WORKERS = 2 #if memory doesnt get too loaded can increase
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-Detection/retinanet_R_50_FPN_1x.yaml")  #TBD, these weights for now
cfg.SOLVER.IMS_PER_BATCH = 1 #number of images per batch per one core
cfg.SOLVER.BASE_LR = 0.001 #
cfg.SOLVER.MOMENTUM = 0.9 #


cfg.SOLVER.WARMUP_ITERS = 100 #lr will be lower for that many iters
cfg.SOLVER.MAX_ITER = 1500 #adjust up if val mAP is still rising, adjust down if overfit
cfg.SOLVER.GAMMA = 0.1 # lr decay
cfg.SOLVER.STEPS = (100,) # number of steps for lr to decay

cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 1 #im per batch
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1 #1 class

cfg.TEST.DETECTIONS_PER_IMAGE = 300 # number of roi per image

cfg.MODEL.RETINANET.NUM_CLASSES = 1

USE_GPU = True

if USE_GPU and torch.cuda.is_available():
    print('using device: cuda')
else:
    print('using device: cpu')

#look at the data
ds_train_meta = json_to_ds("/content/seg_train.json")

for d in random.sample(ds_train_meta, 1):
    img = cv2.imread(d["file_name"])
    visualizer = Visualizer(img[:, :, ::-1], metadata=cell_meta, scale=0.5)
    vis = visualizer.draw_dataset_dict(d)
    cv2_imshow(vis.get_image()[:, :, ::-1])

#training
os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = DefaultTrainer(cfg) 
trainer.resume_or_load(resume=False)
trainer.train()

# Commented out IPython magic to ensure Python compatibility.
# Look at training curves in tensorboard:
# %load_ext tensorboard
# %tensorboard --logdir output

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext tensorboard

"""inference"""

cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5 
cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.15
cfg.MODEL.RETINANET.IOU_THRESHOLDS = [0.7, 0.7]  
cfg.DATASETS.TEST = ("ds9_val",)
predictor = DefaultPredictor(cfg)

import pprint

dataset_dicts = json_to_ds("/content/seg_val.json")
for d in random.sample(dataset_dicts, 1):    
    im = cv2.imread(d["file_name"])
    outputs = predictor(im)
    pprint.pprint(outputs)
    v = Visualizer(im[:, :, ::-1], metadata=cell_meta, scale=0.8, instance_mode=ColorMode.IMAGE)
    v = v.draw_instance_predictions(outputs["instances"].to("cpu"))
    cv2_imshow(v.get_image()[:, :, ::-1])

evaluator = COCOEvaluator("ds9_val", ("bbox", "segm"), False, output_dir="./output/")
val_loader = build_detection_test_loader(cfg, "ds9_val")
print(inference_on_dataset(predictor.model, val_loader, evaluator))

print(cfg.dump())

f = open('config.yml', 'w')
f.write(cfg.dump())
f.close()

"""## Classification

dataset shuffle
"""



"""set up"""

import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import torch.optim as optim
import torchvision.transforms.functional as TF
import time
import os

#hyperparameters
batch_size = 64
epochCount = 20
learningRate = 0.001

# import the handwrittenmathsymbols set using the ImageFolder dataset class
dataset_util = torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/sipakmed_dataset/classification_dataset', transform=transforms.ToTensor())

# dataloaders "represent a Python iterable over a dataset"
dataloader = torch.utils.data.DataLoader(dataset_util, batch_size=batch_size, num_workers=2, shuffle=True)

dataset_total_len = len(dataset_util)
batch_total_num = int(dataset_total_len / batch_size)
print(dataset_total_len, batch_total_num)

classes = ["Dyskeratotic", "Koilocytotic", "Metaplastic", "Parabasal", "Superficial-Intermediate"]

# taken from https://stackoverflow.com/a/56512552
def imshow(image, ax=None):
  if ax is None:
      fig, ax = plt.subplots()
  image = image.numpy().transpose((1, 2, 0))

  ax.imshow(image)
  ax.spines['top'].set_visible(False)
  ax.spines['right'].set_visible(False)
  ax.spines['left'].set_visible(False)
  ax.spines['bottom'].set_visible(False)
  ax.tick_params(axis='both', length=0)
  ax.set_xticklabels('')
  ax.set_yticklabels('')

  return ax

iter_test = iter(dataloader)
img, lbl = iter_test.next()
display(img[0], classes[lbl[0]])
imshow(img[0])

mean = 0.
std = 0.


for batch_idx, data in enumerate(dataloader, 0):
    if (batch_idx % 10 == 9):
      print("%d / %d" % (batch_idx + 1, total_batch_num))

    image, label = data
    batchSize = image.size(0)
    image = image.view(batchSize, image.size(1), -1)
    mean += image.mean(2).sum(0)
    std += image.std(2).sum(0)
  
mean /= len(dataset_util)
std /= len(dataset_util)
print(mean, std)

classlen = len(classes)
classlen

# show grid of images from dataset
images, labels = next(iter(dataloader))

imshow(torchvision.utils.make_grid(images[:4], nrow=2))
for lbl in labels[:4]:
  print(classes[lbl.item() - 1])

datalen = len(dataset_util)
print(datalen)

mean, std

dataset = torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/sipakmed_dataset/classification_dataset', transform=
                                           transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean, std)]))
trainlen = int(datalen * 0.7)
evallen = datalen - trainlen

trainset, evalset = torch.utils.data.random_split(dataset, [trainlen, evallen])
vallen = int(evallen / 2)
testlen = evallen - vallen

valset, testset  = torch.utils.data.random_split(evalset, [vallen, testlen])

trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)
valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=2)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)

print(len(trainset))
print(len(valset))
print(len(testset))

image,_ = iter(trainloader).next()
image.size()

i = np.random.randint(0, batch_size - 1)
imshow(image[i])

print(len(trainset))
print(len(valset))
print(len(testset))
epoch_count_train = int(len(trainset) / batch_size)
epoch_count_val = int(len(valset) / batch_size)
print(epoch_count_train)
print(epoch_count_val)

"""model"""

class cell_classifier(nn.Module):
  def __init__(self):
    super(cell_classifier, self).__init__()

    self.conv1 = nn.Conv2d(3, 8, 3) # input, output, kernel
    self.conv2 = nn.Conv2d(8, 16, 3)
    self.conv3 = nn.Conv2d(16, 32, 3)
    self.conv4 = nn.Conv2d(32, 64, 4)
    self.conv5 = nn.Conv2d(64, 256, 5)

    self.pool1 = nn.MaxPool2d(2, 2) #kernel, stride, padding
    self.pool2 = nn.MaxPool2d(2, 2, 1)
    self.pool3 = nn.MaxPool2d(2, 2)
    self.pool4 = nn.MaxPool2d(2, 2, 1)

    self.fc1 = nn.Linear(256, 64)
    self.fc2 = nn.Linear(64, 16)
    self.fc3 = nn.Linear(16, 5)

    torch.nn.init.xavier_uniform_(self.conv1.weight)
    torch.nn.init.xavier_uniform_(self.conv2.weight)
    torch.nn.init.xavier_uniform_(self.conv3.weight)
    torch.nn.init.xavier_uniform_(self.conv4.weight)
    torch.nn.init.xavier_uniform_(self.conv5.weight)
    torch.nn.init.xavier_uniform_(self.fc1.weight)
    torch.nn.init.xavier_uniform_(self.fc2.weight)
    torch.nn.init.xavier_uniform_(self.fc3.weight)
    
  def forward(self, x):
    x = F.relu(self.conv1(x))
    x = self.pool1(x)
    x = F.relu(self.conv2(x))
    x = self.pool2(x)
    x = F.relu(self.conv3(x))
    x = self.pool3(x)
    x = F.relu(self.conv4(x))
    x = self.pool4(x)
    x = F.relu(self.conv5(x))
    x = x.view(-1, 256)
    x = self.fc1(x)
    x = F.relu(x)
    x = self.fc2(x)
    x = F.relu(x)
    x = self.fc3(x)
    return x

net = cell_classifier()

net

params = list(net.parameters())
print(len(params))
for i in range(10):
  print(params[i].size())

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(params, lr = learningRate, betas = (0.9,0.999), eps = 1e-6)

"""training"""

tloss_plt = []
train_acc_plot = []
correct_train = 0.0
total_train = 0.0

vloss_plt = []
val_acc_plot = []
correct_val = 0.0
total_val = 0.0


for epoch in range(epochCount):

    running_tloss = 0.0
    running_vloss = 0.0
    avg_perbatch_acc_train = 0.0
    avg_perbatch_acc_val = 0.0
    start = time.time()

    print('epoch', epoch + 1)

    net.train(mode=True)
    print('training cycle')
    for i, data in enumerate(trainloader, 0):
      inputs, labels = data
      labels = labels - 1

      optimizer.zero_grad()

      outputs = net(inputs)
      loss = criterion(outputs, labels)
      loss.backward()
      optimizer.step()

      perbatch_acc_train = 0.0
      _, predicted_train = torch.max(outputs.data, 1)
      total_train += labels.size(0)
      correct_train += (predicted_train == labels).sum().item()
      perbatch_acc_train = correct_train / total_train
      avg_perbatch_acc_train += perbatch_acc_train / 2 # 100 * accuracy / 200

      running_tloss += loss.item()

      if i % 50 == 49:
         tloss_plt.append(loss.item())
         
      if i % 200 == 199:
        print('[%d, %5d] train loss: %.6f, avg_train_acc: %.2f %%' % (epoch + 1, i + 1, running_tloss / 200, avg_perbatch_acc_train))
        train_acc_plot.append(avg_perbatch_acc_train)
        running_tloss = 0.0
        avg_perbatch_acc_train = 0.0

    net.train(mode=False)
    print('evaluation cycle')
    with torch.no_grad():
      for i, data in enumerate(valloader, 0):
        inputs, labels = data
        labels = labels - 1

        outputs = net(inputs)
        loss = criterion(outputs, labels)
        
        perbatch_acc_val = 0.0
        _, predicted_val = torch.max(outputs.data, 1)
        total_val += labels.size(0)
        correct_val += (predicted_val == labels).sum().item()
        perbatch_acc_val = correct_val / total_val
        avg_perbatch_acc_val += perbatch_acc_val / 2

        running_vloss += loss.item()

        if i % 50 == 49:
         vloss_plt.append(loss.item())
         
        if i % 200 == 199:
          print('[%d, %5d] val loss: %.6f, avg_val_acc: %.2f %%' % (epoch + 1, i + 1, running_vloss / 200, avg_perbatch_acc_val))
          val_acc_plot.append(avg_perbatch_acc_val)
          running_vloss = 0.0
          avg_perbatch_acc_val = 0.0

    end = time.time()
    print('time spent on epoch %d: %.2f s' % (epoch + 1,end - start))
print('sector clear!')

valloader_prediction = torch.utils.data.DataLoader(valset, batch_size=8, shuffle=True, num_workers=2)

dataiter = iter(valloader_prediction)
images, labels = dataiter.next()
labels = labels - 1
tf1 = tf.Compose([transforms.Normalize(0, 1 / std), transforms.Normalize(-mean, 1)])
images = tf1(images)

imshow(torchvision.utils.make_grid(images, nrow=4))
print('============ \n ground truth labels:')
for lbl in labels[:8]:
  print(classes[lbl.item()])

outputs = net(images)

_,predicted = torch.max(outputs, 1)
print('============ \n predicted:')
for lbl in labels[:8]:
  print(classes[lbl.item()])
print("============")

correct_val = 0
total_val = 0
avg_val_acc = 0.0
avg_loss_val = 0.0

with torch.no_grad():
    for data in valloader:
        images, labels = data
        labels = labels - 1
        outputs = net(images)

        _, predicted_val = torch.max(outputs.data, 1)
        total_val += labels.size(0)
        correct_val += (predicted_val == labels).sum().item()
        avg_val_acc = 100 * correct_val / total_val

print('validation accuracy %.2f %%, error rate %.2f %%' % (avg_val_acc, 100 - avg_val_acc))

correct_test = 0
total_test = 0
avg_test_acc = 0.0
avg_loss_test = 0.0

with torch.no_grad():
    for data in testloader:
        images, labels = data
        labels = labels - 1
        outputs = net(images)

        _, predicted_test = torch.max(outputs.data, 1)
        total_test += labels.size(0)
        correct_test += (predicted_test == labels).sum().item()
        avg_test_acc = 100 * correct_test / total_test

print('test accuracy %.2f %%, error rate %.2f %%' % (avg_test_acc, 100 - avg_test_acc))

"""## Segmentation another approach"""

